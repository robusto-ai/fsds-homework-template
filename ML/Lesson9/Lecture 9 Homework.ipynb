{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9: Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Implement Bagging Aggregation\n",
    "\n",
    "**Task**: Write a Python function bagging_aggregation that takes a list of predictions from multiple models for a classification task and outputs the final aggregated prediction using majority voting.\n",
    "\n",
    "- Input: A list of lists, where each inner list contains predictions from a single model.\n",
    "\n",
    "- Output: A list of final predictions (aggregated using majority voting).\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "predictions = [[1, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 1]] # predictions from 5 models for 3 samples\n",
    "output = [0, 0, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def bagging_aggregation(predictions):\n",
    "    aggregated = []\n",
    "    for i in range(len(predictions[0])):\n",
    "        column = [pred[i] for pred in predictions]\n",
    "        aggregated.append(Counter(column).most_common(1)[0][0])\n",
    "    return aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestBaggingAggregation(unittest.TestCase):\n",
    "    def test_majority_voting(self):\n",
    "        self.assertEqual(bagging_aggregation([[1, 0, 1], [1, 1, 1], [0, 0, 1]]), [1, 0, 1])\n",
    "    \n",
    "    def test_tie_handling(self):\n",
    "        self.assertEqual(bagging_aggregation([[1, 0], [0, 1], [1, 0]]), [1, 0])  # Majority voting resolves ties arbitrarily.\n",
    "    \n",
    "    def test_single_model(self):\n",
    "        self.assertEqual(bagging_aggregation([[1, 1, 1]]), [1, 1, 1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Boosting Weight Update\n",
    "\n",
    "**Task**: Write a Python function update_weights that updates weights for a boosting algorithm. Given a list of current weights, a list of binary predictions, and the actual labels, the function adjusts the weights by increasing the weight of misclassified samples.\n",
    "\n",
    "- Input: A list of current weights, a list of predictions, and a list of true labels.\n",
    "\n",
    "- Output: A list of updated weights.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "# Input: \n",
    "weights=[0.2, 0.3, 0.5]\n",
    "predictions=[1, 0, 1]\n",
    "labels=[1, 1, 0]\n",
    "\n",
    "# Output: \n",
    "output = [0.2, 0.6, 1.0]  # (weights are normalized)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, predictions, labels):\n",
    "    updated_weights = [\n",
    "        weight * 2 if pred != label else weight\n",
    "        for weight, pred, label in zip(weights, predictions, labels)\n",
    "    ]\n",
    "    total_weight = sum(updated_weights)\n",
    "    return [w / total_weight for w in updated_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestUpdateWeights(unittest.TestCase):\n",
    "    def test_weight_update(self):\n",
    "        self.assertEqual(update_weights([0.2, 0.3, 0.5], [1, 0, 1], [1, 1, 0]), [0.2, 0.6, 1.0])\n",
    "    \n",
    "    def test_all_correct_predictions(self):\n",
    "        self.assertEqual(update_weights([0.2, 0.3, 0.5], [1, 1, 0], [1, 1, 0]), [0.2, 0.3, 0.5])\n",
    "    \n",
    "    def test_all_incorrect_predictions(self):\n",
    "        self.assertEqual(update_weights([0.2, 0.3, 0.5], [0, 0, 1], [1, 1, 0]), [0.25, 0.375, 0.625])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Stacking Meta-Model Predictions\n",
    "\n",
    "**Task**: Write a Python function stacking_predictions that takes the predictions of multiple models (as a 2D list) and a meta-model (as a callable function) to predict the final output.\n",
    "\n",
    "- Input: A 2D list of predictions (where each row is from a model) and a callable meta-model (e.g., a lambda function).\n",
    "\n",
    "- Output: A list of final predictions from the meta-model.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "# Input: \n",
    "predictions=[[0.8, 0.1], [0.6, 0.4], [0.7, 0.2]]\n",
    "meta_model=lambda x: 1 if sum(x)/len(x) > 0.5 else 0\n",
    "\n",
    "# Output: \n",
    "output = [1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_predictions(predictions, meta_model):\n",
    "    transposed = list(zip(*predictions))\n",
    "    return [meta_model(row) for row in transposed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestStackingPredictions(unittest.TestCase):\n",
    "    def test_average_meta_model(self):\n",
    "        meta_model = lambda x: 1 if sum(x) / len(x) > 0.5 else 0\n",
    "        self.assertEqual(stacking_predictions([[0.8, 0.1], [0.6, 0.4], [0.7, 0.2]], meta_model), [1, 0])\n",
    "    \n",
    "    def test_majority_vote_meta_model(self):\n",
    "        meta_model = lambda x: 1 if sum(x) > len(x) / 2 else 0\n",
    "        self.assertEqual(stacking_predictions([[1, 0], [1, 1], [0, 0]], meta_model), [1, 0])\n",
    "    \n",
    "    def test_single_model(self):\n",
    "        meta_model = lambda x: x[0]\n",
    "        self.assertEqual(stacking_predictions([[1, 0]], meta_model), [1, 0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
