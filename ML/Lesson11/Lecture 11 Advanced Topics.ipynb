{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11: Advanced Machine Learning Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Implement Stratified K-Fold Cross-Validation\n",
    "\n",
    "**Task**: Write a function ```stratified_kfold(data, labels, k)``` that splits the data into k folds while maintaining the class distribution in each fold.\n",
    "\n",
    "- Input:\n",
    "\n",
    "    - data: List of data samples (e.g., [[1, 2], [3, 4], ...]).\n",
    "    \n",
    "    - labels: List of class labels (e.g., [0, 1, 1, 0, ...]).\n",
    "    \n",
    "    - k: Number of folds.\n",
    "\n",
    "- Output: A list of k tuples. Each tuple contains (train_indices, test_indices).\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "# Input\n",
    "data = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "labels = [0, 1, 0, 1, 0]\n",
    "k = 2\n",
    "\n",
    "# Output: \n",
    "[([2, 4], [0, 1, 3]), ([0, 1, 3], [2, 4])]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def stratified_kfold(data, labels, k):\n",
    "    class_indices = defaultdict(list)\n",
    "    for i, label in enumerate(labels):\n",
    "        class_indices[label].append(i)\n",
    "\n",
    "    folds = [[] for _ in range(k)]\n",
    "    for indices in class_indices.values():\n",
    "        for i, index in enumerate(indices):\n",
    "            folds[i % k].append(index)\n",
    "\n",
    "    result = []\n",
    "    for i in range(k):\n",
    "        test_indices = folds[i]\n",
    "        train_indices = [idx for j, fold in enumerate(folds) if j != i for idx in fold]\n",
    "        result.append((train_indices, test_indices))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stratified_kfold_balanced_classes():\n",
    "    data = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "    labels = [0, 1, 0, 1]\n",
    "    k = 2\n",
    "    result = stratified_kfold(data, labels, k)\n",
    "    assert len(result) == 2\n",
    "    assert all(len(set(train).intersection(set(test))) == 0 for train, test in result)\n",
    "\n",
    "def test_stratified_kfold_imbalanced_classes():\n",
    "    data = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "    labels = [0, 1, 0, 1, 0]\n",
    "    k = 2\n",
    "    result = stratified_kfold(data, labels, k)\n",
    "    assert len(result) == 2\n",
    "    assert len(result[0][1]) == 2\n",
    "    assert len(result[1][1]) == 3\n",
    "\n",
    "def test_stratified_kfold_single_class():\n",
    "    data = [[1, 2], [3, 4], [5, 6]]\n",
    "    labels = [1, 1, 1]\n",
    "    k = 2\n",
    "    result = stratified_kfold(data, labels, k)\n",
    "    assert len(result) == 2\n",
    "    assert len(result[0][1]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Implement SMOTE\n",
    "\n",
    "**Task**: Write a function smote(data, labels, target_class) to generate synthetic samples for the target_class.\n",
    "\n",
    "- Input:\n",
    "\n",
    "    - data: List of data samples (e.g., [[1, 2], [3, 4], ...]).\n",
    "    \n",
    "    - labels: List of class labels (e.g., [0, 1, 1, 0, ...]).\n",
    "    \n",
    "    - target_class: The class for which synthetic samples will be generated.\n",
    "\n",
    "- Output: Tuple of updated data and labels including synthetic samples.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "# Input\n",
    "data = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "labels = [0, 1, 0, 1]\n",
    "target_class = 0\n",
    "\n",
    "# Output: \n",
    "([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4]], [0, 1, 0, 1, 0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def smote(data, labels, target_class):\n",
    "    target_indices = [i for i, label in enumerate(labels) if label == target_class]\n",
    "    synthetic_data = []\n",
    "    while len(synthetic_data) < len(labels) - len(target_indices):\n",
    "        i, j = random.sample(target_indices, 2)\n",
    "        new_sample = [(x + y) / 2 for x, y in zip(data[i], data[j])]\n",
    "        synthetic_data.append(new_sample)\n",
    "\n",
    "    synthetic_labels = [target_class] * len(synthetic_data)\n",
    "    return data + synthetic_data, labels + synthetic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_smote_balanced():\n",
    "    data = [[1, 2], [3, 4]]\n",
    "    labels = [0, 1]\n",
    "    result_data, result_labels = smote(data, labels, 0)\n",
    "    assert len(result_data) == 3\n",
    "    assert result_labels.count(0) == 2\n",
    "\n",
    "def test_smote_imbalanced():\n",
    "    data = [[1, 2], [3, 4], [5, 6]]\n",
    "    labels = [0, 1, 0]\n",
    "    result_data, result_labels = smote(data, labels, 0)\n",
    "    assert len(result_data) == 4\n",
    "    assert result_labels.count(0) == 3\n",
    "\n",
    "def test_smote_multiple_classes():\n",
    "    data = [[1, 2], [3, 4], [5, 6]]\n",
    "    labels = [0, 1, 1]\n",
    "    result_data, result_labels = smote(data, labels, 1)\n",
    "    assert len(result_data) > len(data)\n",
    "    assert result_labels.count(1) > labels.count(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Build a Data Pipeline\n",
    "\n",
    "**Task**: Write a function build_pipeline() to create a pipeline that performs the following steps:\n",
    "\n",
    "1. Imputes missing values.\n",
    "\n",
    "2. Standardizes numerical data.\n",
    "\n",
    "3. Encodes categorical data.\n",
    "\n",
    "4. Trains a logistic regression model.\n",
    "\n",
    "**Input and Output Format**:\n",
    "\n",
    "- Input: Dataset as a Pandas DataFrame.\n",
    "\n",
    "- Output: Trained pipeline ready for predictions.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "# Input\n",
    "data = pd.DataFrame({\n",
    "    'age': [25, None, 30],\n",
    "    'gender': ['M', 'F', 'M'],\n",
    "    'income': [50000, 60000, None],\n",
    "    'target': [1, 0, 1]\n",
    "})\n",
    "\n",
    "# Output: Fitted pipeline object.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def build_pipeline():\n",
    "    numeric_features = ['age', 'income']\n",
    "    categorical_features = ['gender']\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline_fit():\n",
    "    pipeline = build_pipeline()\n",
    "    data = pd.DataFrame({\n",
    "        'age': [25, None, 30],\n",
    "        'gender': ['M', 'F', 'M'],\n",
    "        'income': [50000, 60000, None],\n",
    "        'target': [1, 0, 1]\n",
    "    })\n",
    "    pipeline.fit(data[['age', 'gender', 'income']], data['target'])\n",
    "\n",
    "def test_pipeline_transform():\n",
    "    pipeline = build_pipeline()\n",
    "    data = pd.DataFrame({\n",
    "        'age': [25, None, 30],\n",
    "        'gender': ['M', 'F', 'M'],\n",
    "        'income': [50000, 60000, None],\n",
    "        'target': [1, 0, 1]\n",
    "    })\n",
    "    pipeline.fit(data[['age', 'gender', 'income']], data['target'])\n",
    "    transformed = pipeline.named_steps['preprocessor'].transform(data[['age', 'gender', 'income']])\n",
    "    assert transformed.shape[1] > 0\n",
    "\n",
    "def test_pipeline_prediction():\n",
    "    pipeline = build_pipeline()\n",
    "    data = pd.DataFrame({\n",
    "        'age': [25, None, 30],\n",
    "        'gender': ['M', 'F', 'M'],\n",
    "        'income': [50000, 60000, None],\n",
    "        'target': [1, 0, 1]\n",
    "    })\n",
    "    pipeline.fit(data[['age', 'gender', 'income']], data['target'])\n",
    "    predictions = pipeline.predict([[30, 'F', 70000]])\n",
    "    assert len(predictions) == 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
